{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DUI DNN\n",
    "Deep Urban Interaction - Deep Neural Network  \n",
    "Interaction Classification with OpenCV, OpenPose, and PyTorch  \n",
    "Ryan Yan Zhang <ryanz@mit.edu>  \n",
    "City Science, MIT Media Lab  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "from pprint import pprint\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image from video with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose json from image with OpenPose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## People Bounding box from OpenPose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction Classification with PyTorch DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets.folder import ImageFolder, default_loader\n",
    "from torchvision import models\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training helpers\n",
    "def get_trainable(model_params):\n",
    "    return (p for p in model_params if p.requires_grad)\n",
    "\n",
    "\n",
    "def get_frozen(model_params):\n",
    "    return (p for p in model_params if not p.requires_grad)\n",
    "\n",
    "\n",
    "def all_trainable(model_params):\n",
    "    return all(p.requires_grad for p in model_params)\n",
    "\n",
    "\n",
    "def all_frozen(model_params):\n",
    "    return all(not p.requires_grad for p in model_params)\n",
    "\n",
    "\n",
    "def freeze_all(model_params):\n",
    "    for param in model_params:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation transforms\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "IMG_SIZE = 224  #224  #defined by NN model input\n",
    "_mean = [0.485, 0.456, 0.406]\n",
    "_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "train_trans = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE,IMG_SIZE)),  #256  #(IMG_SIZE, IMG_SIZE)  # some images are pretty small\n",
    "    #transforms.RandomCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(.3, .3, .3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(_mean, _std),\n",
    "])\n",
    "val_trans = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE,IMG_SIZE)),  #256  #(IMG_SIZE, IMG_SIZE)\n",
    "    #transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(_mean, _std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set\n",
    "train_ds = ImageFolder(\"../data/raw/DUI/train\", transform=train_trans, loader=default_loader)\n",
    "val_ds = ImageFolder(\"../data/raw/DUI/valid\", transform=train_trans, loader=default_loader)\n",
    "#print(f'len(train_ds): {len(train_ds)}, len(val_ds): {len(val_ds)}')\n",
    "\n",
    "BATCH_SIZE = 128  #2  #256  #512  #32  #220 for resnet152 on Dell Presison 5520 laptop, 400 for resnet18\n",
    "\n",
    "n_classes = 2\n",
    "\n",
    "# DataLoader\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = models.resnet18(pretrained=True)\n",
    "#model = models.resnet50(pretrained=True)\n",
    "#model = models.resnet101(pretrained=True)\n",
    "#model = models.resnet152(pretrained=True)\n",
    "\n",
    "# Transfer learning or whole model training\n",
    "# Opt.1 Transfer learning\n",
    "'''\n",
    "# Freeze all parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "#print(fall_frozen(model.parameters()): {all_frozen(model.parameters())}')\n",
    "\n",
    "model.fc = nn.Linear(512, n_classes)  # according to the model, 512 for resnet18, 2048 for resnet50 & resnet101 & resnet152\n",
    "\n",
    "model = model.to(device)\n",
    "'''\n",
    "\n",
    "# Opt.2 Whole model training\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    get_trainable(model.parameters()),\n",
    "    # model.fc.parameters(),\n",
    "    lr=0.001,\n",
    "    # momentum=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop\n",
    "if False:\n",
    "    N_EPOCHS = 10  #1  #2  #10\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        # start epoch\n",
    "        start_time = time.time()\n",
    "        start_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\"Epoch {epoch+1}/{N_EPOCHS}\")\n",
    "        print(f'  Start Time: {start_datetime}')\n",
    "\n",
    "        # Train\n",
    "        model.train()  # IMPORTANT\n",
    "\n",
    "        running_loss, correct = 0.0, 0\n",
    "        for X, y in train_dl:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # with torch.set_grad_enabled(True):\n",
    "            y_ = model(X)\n",
    "            loss = criterion(y_, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Statistics\n",
    "            print(f\"    batch loss: {loss.item():0.3f}\")\n",
    "            _, y_label_ = torch.max(y_, 1)\n",
    "            correct += (y_label_ == y).sum().item()\n",
    "            running_loss += loss.item() * X.shape[0]\n",
    "\n",
    "        print(f\"  Train Loss: {running_loss / len(train_dl.dataset)}\")\n",
    "        print(f\"  Train Acc:  {correct / len(train_dl.dataset)}\")\n",
    "\n",
    "\n",
    "        # Eval\n",
    "        model.eval()  # IMPORTANT\n",
    "\n",
    "        running_loss, correct = 0.0, 0\n",
    "        with torch.no_grad():  # IMPORTANT\n",
    "            for X, y in val_dl:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                y_ = model(X)\n",
    "\n",
    "                _, y_label_ = torch.max(y_, 1)\n",
    "                correct += (y_label_ == y).sum().item()\n",
    "\n",
    "                loss = criterion(y_, y)\n",
    "                running_loss += loss.item() * X.shape[0]\n",
    "\n",
    "        print(f\"  Valid Loss: {running_loss / len(val_dl.dataset)}\")\n",
    "        print(f\"  Valid Acc:  {correct / len(val_dl.dataset)}\")\n",
    "\n",
    "        # end epoch\n",
    "        end_time = time.time()\n",
    "        end_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        time_elapsed = end_time - start_time\n",
    "        datetime_elapsed = str(datetime.timedelta(seconds = time_elapsed))\n",
    "        print(f'  End Time: {end_datetime}')\n",
    "        print(f'  Time Elapsed: {datetime_elapsed}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with Trained Model\n",
    "\n",
    "\n",
    "# save the trained model weights\n",
    "model_weights_path = '../data/saved_model_weights/resnet18_whole'\n",
    "\n",
    "# save a trained model weights\n",
    "if False:\n",
    "    torch.save(model.state_dict(), model_weights_path)\n",
    "\n",
    "# load the trained model weights\n",
    "if True:\n",
    "    from torchvision import models\n",
    "    model = models.resnet18(pretrained=True)  # resnet50, 101, 152\n",
    "    model.load_state_dict(torch.load(model_weights_path))\n",
    "    model = model.to(device)\n",
    "\n",
    "\n",
    "# test data set\n",
    "test_ds = ImageFolder(\"../data/raw/DUI/test\", transform=val_trans, loader=default_loader)\n",
    "#print(f'len(test_ds) = {len(test_ds)}. ')\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "#print(f'test_ds[99]: \\n{test_ds[99]}')\n",
    "#print(f'test_ds[99][1]: \\n{test_ds[99][1]}')\n",
    "\n",
    "\n",
    "# predict\n",
    "model.eval()  # IMPORTANT\n",
    "with torch.no_grad():  # IMPORTANT\n",
    "    for X, y in test_dl:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        #print(f'y: \\t\\t\\t{y}')\n",
    "\n",
    "        y_ = model(X)\n",
    "        _, y_label_ = torch.max(y_, 1)\n",
    "        #print(f'y_label_: \\t\\t{y_label_}')\n",
    "        \n",
    "        is_correct = 'correct' if y_label_ == y else 'wrong'\n",
    "        #print(f'is_correct: \\t{is_correct}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
